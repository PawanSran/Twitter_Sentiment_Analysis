{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./train_90.txt', skiprows = 1, names= [\"ItemID\", \"Sentiment\", \"SentimentSource\", \"SentimentText\"])\n",
    "\n",
    "test_df = pd.read_csv('./test_10.txt', skiprows = 1, names= [\"ItemID\", \"Sentiment\", \"SentimentSource\", \"SentimentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pawanjeetkaur/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt\n",
    "\n",
    "def clean_data(text):\n",
    "    text['tidy_tweet'] = np.vectorize(remove_pattern)(text['SentimentText'], \"@[\\w]*\")\n",
    "    text['tidy_tweet'] = text['tidy_tweet'].apply(lambda x: x.lower())\n",
    "    text['tidy_tweet'] = text['tidy_tweet'].str.replace(\"[^a-z0-9#]\", \" \")\n",
    "    text['tokenized_tweet'] = text['tidy_tweet'].apply(lambda x: x.split())\n",
    "    text['tokenized_tweet'] = text['tokenized_tweet'].apply(lambda x: [i for i in x if i not in stop])\n",
    "    text['tokenized_tweet'] = text['tokenized_tweet'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "    text['tokenized_tweet'] = text['tokenized_tweet'].apply(lambda x: ' '.join([w for w in x]))\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = clean_data(train_df)\n",
    "cleaned_data_test = clean_data(test_df)\n",
    "y_test = cleaned_data_test['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           sad apl friend\n",
      "1                                    miss new moon trailer\n",
      "2                                         omg alreadi 7 30\n",
      "3        omgaga im sooo im gunna cri dentist sinc 11 su...\n",
      "4                                        think mi bf cheat\n",
      "                               ...                        \n",
      "89984    gnome hat problem finish size pointi top mama ...\n",
      "89985    saw linn bakeri thought veggi friendli worri f...\n",
      "89986                                           would love\n",
      "89987                                                 evid\n",
      "89988    spine thing sound good back exercis fun best l...\n",
      "Name: tokenized_tweet, Length: 89989, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(train_df[\"SentimentText\"][89985])\n",
    "print(cleaned_data['tokenized_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=10, stop_words='english')\n",
    "\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(cleaned_data['tokenized_tweet']).toarray()\n",
    "\n",
    "tfidf_test = tfidf_vectorizer.transform(cleaned_data_test['tokenized_tweet']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>is so sad for my apl frie...</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>i missed the new moon trail...</td>\n",
       "      <td>miss new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg its already 7 30  o</td>\n",
       "      <td>omg alreadi 7 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga  im sooo  im gunna cry  i ...</td>\n",
       "      <td>omgaga im sooo im gunna cri dentist sinc 11 su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>i think mi bf is cheating on me      ...</td>\n",
       "      <td>think mi bf cheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89984</td>\n",
       "      <td>89996</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@clevercatsknit Re: gnome hat. Was the problem...</td>\n",
       "      <td>re  gnome hat  was the problem the finished s...</td>\n",
       "      <td>gnome hat problem finish size pointi top mama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89985</td>\n",
       "      <td>89997</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@clevercatsknit Saw Linnes Bakery but thought ...</td>\n",
       "      <td>saw linnes bakery but thought it not too vegg...</td>\n",
       "      <td>saw linn bakeri thought veggi friendli worri f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89986</td>\n",
       "      <td>89998</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@cleverdaisies I would LOVE to!!!</td>\n",
       "      <td>i would love to</td>\n",
       "      <td>would love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89987</td>\n",
       "      <td>89999</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@cleverick evidently not</td>\n",
       "      <td>evidently not</td>\n",
       "      <td>evid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89988</td>\n",
       "      <td>90000</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>@cleverindie This spine thing sounds no good  ...</td>\n",
       "      <td>this spine thing sounds no good  back exercis...</td>\n",
       "      <td>spine thing sound good back exercis fun best l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89989 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment SentimentSource  \\\n",
       "0           1          0    Sentiment140   \n",
       "1           2          0    Sentiment140   \n",
       "2           3          1    Sentiment140   \n",
       "3           4          0    Sentiment140   \n",
       "4           5          0    Sentiment140   \n",
       "...       ...        ...             ...   \n",
       "89984   89996          1    Sentiment140   \n",
       "89985   89997          1    Sentiment140   \n",
       "89986   89998          1    Sentiment140   \n",
       "89987   89999          0    Sentiment140   \n",
       "89988   90000          0    Sentiment140   \n",
       "\n",
       "                                           SentimentText  \\\n",
       "0                           is so sad for my APL frie...   \n",
       "1                         I missed the New Moon trail...   \n",
       "2                                omg its already 7:30 :O   \n",
       "3                .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4               i think mi bf is cheating on me!!!   ...   \n",
       "...                                                  ...   \n",
       "89984  @clevercatsknit Re: gnome hat. Was the problem...   \n",
       "89985  @clevercatsknit Saw Linnes Bakery but thought ...   \n",
       "89986                 @cleverdaisies I would LOVE to!!!    \n",
       "89987                          @cleverick evidently not    \n",
       "89988  @cleverindie This spine thing sounds no good  ...   \n",
       "\n",
       "                                              tidy_tweet  \\\n",
       "0                           is so sad for my apl frie...   \n",
       "1                         i missed the new moon trail...   \n",
       "2                                omg its already 7 30  o   \n",
       "3                   omgaga  im sooo  im gunna cry  i ...   \n",
       "4               i think mi bf is cheating on me      ...   \n",
       "...                                                  ...   \n",
       "89984   re  gnome hat  was the problem the finished s...   \n",
       "89985   saw linnes bakery but thought it not too vegg...   \n",
       "89986                                i would love to       \n",
       "89987                                     evidently not    \n",
       "89988   this spine thing sounds no good  back exercis...   \n",
       "\n",
       "                                         tokenized_tweet  \n",
       "0                                         sad apl friend  \n",
       "1                                  miss new moon trailer  \n",
       "2                                       omg alreadi 7 30  \n",
       "3      omgaga im sooo im gunna cri dentist sinc 11 su...  \n",
       "4                                      think mi bf cheat  \n",
       "...                                                  ...  \n",
       "89984  gnome hat problem finish size pointi top mama ...  \n",
       "89985  saw linn bakeri thought veggi friendli worri f...  \n",
       "89986                                         would love  \n",
       "89987                                               evid  \n",
       "89988  spine thing sound good back exercis fun best l...  \n",
       "\n",
       "[89989 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Implement Logisitic Regression with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf\n",
    "y = cleaned_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X, weight):\n",
    "    z = np.dot(X, weight)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def gradient_descent(X, h, y):\n",
    "    return np.dot(X.T, (h - y)) / y.shape[0]\n",
    "\n",
    "def update_weight_loss(weight, learning_rate, gradient):\n",
    "    return weight - learning_rate * gradient\n",
    "\n",
    "def predict_t(x, theta):\n",
    "    theta_1 = theta[:, np.newaxis]\n",
    "    return sigmoid(x,theta_1)\n",
    "\n",
    "def cal_acc(actual, pred):\n",
    "    predicted_class = ((pred >= 0.5) .astype(int))\n",
    "    predicted_class = predicted_class.flatten()\n",
    "    acc = np.mean(predicted_class == actual)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grad(X, y):\n",
    "    num_iter = 100\n",
    "   \n",
    "    theta = np.zeros(X.shape[1])\n",
    " \n",
    "    for i in range(num_iter):\n",
    "        h = sigmoid(X, theta)\n",
    "        gradient = gradient_descent(X, h, y)\n",
    "        theta = update_weight_loss(theta, 0.1, gradient)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10 - Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Prepare cross validation\n",
    "kfold = KFold(10, True, 1)\n",
    "bestaccuracy = 0\n",
    "theta_final = np.zeros(X.shape[1])\n",
    "\n",
    "# Enumerate splits\n",
    "for train, test in kfold.split(X):\n",
    "    X_train = X[train]\n",
    "    X_validate = X[test]\n",
    "    \n",
    "    Y_train = y[train]\n",
    "    Y_validate = y[test]\n",
    "    \n",
    "    theta_out = run_grad(X_train, Y_train)\n",
    "    \n",
    "    pred = predict_t(X_validate, theta_out)\n",
    "    \n",
    "    acc = cal_acc(Y_validate, pred)\n",
    "    \n",
    "    if(acc > bestaccuracy):\n",
    "        theta_final = theta_out\n",
    "        bestaccuracy = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.17983528e-04 3.96188669e-04 9.77293871e-05 ... 7.12300904e-05\n",
      " 5.67245301e-05 4.92836337e-04]\n",
      "0.7033003667074119\n"
     ]
    }
   ],
   "source": [
    "print(theta_final)\n",
    "print(bestaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4803)\n",
      "(89989, 4803)\n"
     ]
    }
   ],
   "source": [
    "test_out = predict_t(tfidf_test, theta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = cal_acc(y_test, test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "9995    0\n",
      "9996    1\n",
      "9997    0\n",
      "9998    1\n",
      "9999    1\n",
      "Name: Sentiment, Length: 10000, dtype: int64\n",
      "[[0.50056451]\n",
      " [0.50011448]\n",
      " [0.50366968]\n",
      " ...\n",
      " [0.50135158]\n",
      " [0.50520769]\n",
      " [0.50587136]]\n",
      "Average precision-recall score: 0.81\n",
      "Precision score: 0.70\n",
      "Recall score: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, test_out)\n",
    "test_final_out = ((test_out >= 0.5) .astype(int))\n",
    "\n",
    "prec = precision_score(y_test, test_final_out)\n",
    "recall = recall_score(y_test, test_final_out)\n",
    "conf = confusion_matrix(y_test, test_final_out)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "print('Precision score: {0:0.2f}'.format(prec))\n",
    "\n",
    "print('Recall score: {0:0.2f}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
